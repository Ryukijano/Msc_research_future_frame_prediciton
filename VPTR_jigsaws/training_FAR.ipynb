{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sc23gd\\.conda\\envs\\vptr\\lib\\site-packages (from tensorboardX) (1.26.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\sc23gd\\.conda\\envs\\vptr\\lib\\site-packages (from tensorboardX) (24.1)\n",
      "Collecting protobuf>=3.20 (from tensorboardX)\n",
      "  Downloading protobuf-5.27.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.7/101.7 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.27.2-cp310-abi3-win_amd64.whl (426 kB)\n",
      "   ---------------------------------------- 0.0/426.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 426.9/426.9 kB 13.4 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, tensorboardX\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed protobuf-5.27.2 tensorboardX-2.6.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.27.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\VPTR_jigsaws\\\\utils')\n",
    "sys.path.append('C:\\\\VPTR_jigsaws\\\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import VPTREnc, VPTRDec, VPTRDisc, init_weights, VPTRFormerFAR\n",
    "from model import GDL, MSELoss, GANLoss\n",
    "from utils import get_dataloader, save_ckpt, load_ckpt, set_seed, AverageMeters, init_loss_dict, write_summary, resume_training\n",
    "from utils import visualize_batch_clips\n",
    "from utils import get_dataloader, VidToTensor, VidRandomHorizontalFlip, VidRandomVerticalFlip\n",
    "from model import VPTREnc, VPTRDec, VPTRFormerFAR, MSELoss, GDL\n",
    "from dataset import JIGSAWSDataset\n",
    "from pathlib import Path\n",
    "from model import VPTREnc, VPTRDec, VPTRDisc, init_weights, VPTRFormerFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories and parameters\n",
    "ckpt_save_dir = Path('C:\\\\VPTR_jigsaws\\\\jigsaws_suturing\\\\VPTR_ckpts\\\\JIGSAWS_FAR_ckpt')\n",
    "tensorboard_save_dir = Path('C:\\\\VPTR_jigsaws\\\\jigsaws_suturing\\\\VPTR_ckpts\\\\JIGSAWS_FAR_tensorboard')\n",
    "resume_AE_ckpt = Path('C:\\\\VPTR_jigsaws\\\\jigsaws_suturing\\\\VPTR_ckpts\\\\JIGSAWS_ResNetAE_MSEGDLgan_ckpt').joinpath('epoch_100.tar')\n",
    "#resume_ckpt = ckpt_save_dir.joinpath('epoch_100.tar')\n",
    "resume_ckpt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    datefmt='%a, %d %b %Y %H:%M:%S',\n",
    "                    format='%(asctime)s - %(message)s',\n",
    "                    filename=f'{ckpt_save_dir}/train_log.log',\n",
    "                    filemode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "summary_writer = SummaryWriter(tensorboard_save_dir.absolute().as_posix())\n",
    "num_past_frames = 10\n",
    "num_future_frames = 20\n",
    "encH, encW, encC = 8, 8, 528\n",
    "img_channels = 3\n",
    "epochs = 100\n",
    "N = 4\n",
    "#AE_lr = 2e-4\n",
    "Transformer_lr = 1e-4\n",
    "max_grad_norm = 1.0\n",
    "rpe = False\n",
    "lam_gan = 0.001\n",
    "dropout = 0.1\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Init Dataset ###########################\n",
    "data_set_name = 'Suturing'\n",
    "dataset_dir = 'C:\\\\VPTR_jigsaws\\\\jigsaws_suturing\\\\frames_split\\\\'\n",
    "train_loader, test_loader, renorm_transform = get_dataloader(data_set_name, N, dataset_dir, num_past_frames=num_past_frames, num_future_frames=num_future_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "VPTR_Enc = VPTREnc(img_channels, feat_dim=encC, n_downsampling=3).to(device)\n",
    "VPTR_Dec = VPTRDec(img_channels, feat_dim=encC, n_downsampling=3, out_layer='Sigmoid').to(device)\n",
    "VPTR_Transformer = VPTRFormerFAR(num_past_frames, num_future_frames, encH=encH, encW=encW, d_model=encC, nhead=8, num_encoder_layers=12, dropout=dropout, window_size=4, Spatial_FFN_hidden_ratio=4, rpe=rpe).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_T = AdamW(params=VPTR_Transformer.parameters(), lr=Transformer_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoints if available\n",
    "loss_name_list = ['T_MSE', 'T_GDL', 'T_gan', 'T_total', 'Dtotal', 'Dfake', 'Dreal']\n",
    "loss_dict = init_loss_dict(loss_name_list)\n",
    "mse_loss = MSELoss()\n",
    "gdl_loss = GDL(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict, start_epoch = resume_training({'VPTR_Enc': VPTR_Enc, 'VPTR_Dec': VPTR_Dec}, {}, resume_AE_ckpt, loss_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_ckpt:\n",
    "    loss_dict, start_epoch = resume_training({'VPTR_Transformer': VPTR_Transformer}, {'optimizer_T': optimizer_T}, resume_ckpt, loss_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_iter(VPTR_Enc, VPTR_Dec, VPTR_Disc, VPTR_Transformer, optimizer_T, optimizer_D, sample, device, lam_gan, train_flag=True):\n",
    "    past_frames, future_frames = sample\n",
    "    past_frames = past_frames.to(device)\n",
    "    future_frames = future_frames.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = torch.cat([past_frames, future_frames[:, :-1, ...]], dim=1) #concatenate past frames and future frames except the last frame\n",
    "        gt_feats = VPTR_Enc(x) #encode the concatenated frames\n",
    "        \n",
    "    if train_flag:\n",
    "        VPTR_Transformer=VPTR_Transformer.train()\n",
    "        VPTR_Transformer.zero_grad(set_to_none=True)\n",
    "        VPTR_Dec.zero_grad(set_to_none=True)\n",
    "        \n",
    "        pred_future_feats = VPTR_Transformer(gt_feats) #predict the future features\n",
    "        pred_frames = VPTR_Dec(pred_future_feats) #decode the predicted future features\n",
    "        \n",
    "        if optimizer_D is not None:\n",
    "            assert lam_gan is not None, \"Please input lam_gan\"\n",
    "            #update discriminator\n",
    "            VPTR_Disc=VPTR_Disc.train()\n",
    "            for p in VPTR_Disc.parameters():\n",
    "                p.requires_grad_(True)\n",
    "            VPTR_Disc.zero_grad(set_to_none=True)\n",
    "            loss_D, loss_D_fake, loss_D_real = cal_lossD(VPTR_Disc, pred_frames, future_frames, lam_gan)\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "        \n",
    "            for p in VPTR_Disc.parameters():\n",
    "                p.requires_grad_(False)\n",
    "\n",
    "\n",
    "        pred_frames_resized = resize_tensor(pred_frames, (future_frames.shape[-2], future_frames.shape[-1]))\n",
    "        \n",
    "        ##update transformer(generator)\n",
    "        loss_T, T_GDL_loss, T_MSE_loss, loss_T_gan = cal_lossT(pred_frames_resized, torch.cat([past_frames[:, 1:, ...], future_frames], dim=1), VPTR_Disc, lam_gan)\n",
    "        loss_T.backward()\n",
    "        nn.utils.clip_grad_norm_(VPTR_Transformer.parameters(), max_grad_norm, norm_type=2)\n",
    "        optimizer_T.step()\n",
    "\n",
    "    else:\n",
    "        if optimizer_D is not None:\n",
    "            VPTR_Disc=VPTR_Disc.eval()\n",
    "        VPTR_Transformer= VPTR_Transformer.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_future_feats = VPTR_Transformer(gt_feats)\n",
    "            pred_frames = VPTR_Dec(pred_future_feats)\n",
    "            if optimizer_D is not None:\n",
    "                loss_D, loss_D_fake, loss_D_real = cal_lossD(VPTR_Disc, pred_frames, future_frames, lam_gan)\n",
    "            else:\n",
    "                loss_D, loss_D_fake, loss_D_real = torch.zeros(1), torch.zeros(1), torch.zeros(1)\n",
    "                \n",
    "                \n",
    "            pred_frames_resized = resize_tensor(pred_frames, (future_frames.shape[-2], future_frames.shape[-1]))\n",
    "            loss_T, T_GDL_loss, T_MSE_loss, loss_T_gan = cal_lossT(pred_frames, torch.cat([past_frames[:, 1:, ...], future_frames], dim=1), VPTR_Disc, lam_gan)\n",
    "    \n",
    "    if optimizer_D is None:        \n",
    "        loss_D, loss_D_fake, loss_D_real = torch.zeros(1), torch.zeros(1), torch.zeros(1)\n",
    "\n",
    "    iter_loss_dict = {'T_total': loss_T.item(), 'T_MSE': T_MSE_loss.item(), 'T_GDL': T_GDL_loss.item(), 'T_gan': loss_T_gan.item(), 'Dtotal': loss_D.item(), 'Dfake': loss_D_fake.item(), 'Dreal': loss_D_real.item()}\n",
    "    \n",
    "    return iter_loss_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VPTR_Disc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m EpochAveMeter \u001b[38;5;241m=\u001b[39m AverageMeters(loss_name_list)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     iter_loss_dict \u001b[38;5;241m=\u001b[39m single_iter(VPTR_Enc, VPTR_Dec, \u001b[43mVPTR_Disc\u001b[49m, VPTR_Transformer, optimizer_T, optimizer_D, sample, device, lam_gan, train_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     EpochAveMeter\u001b[38;5;241m.\u001b[39miter_update(iter_loss_dict)\n\u001b[0;32m      9\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m EpochAveMeter\u001b[38;5;241m.\u001b[39mepoch_update(loss_dict, epoch, train_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VPTR_Disc' is not defined"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(start_epoch + 1, start_epoch + epochs + 1):\n",
    "    epoch_st = datetime.now()\n",
    "    EpochAveMeter = AverageMeters(loss_name_list)\n",
    "    for idx, sample in enumerate(train_loader, 0):\n",
    "        iter_loss_dict = single_iter(VPTR_Enc, VPTR_Dec, VPTR_Disc, VPTR_Transformer, optimizer_T, optimizer_D, sample, device, lam_gan, train_flag=True)\n",
    "        EpochAveMeter.iter_update(iter_loss_dict)\n",
    "\n",
    "    loss_dict = EpochAveMeter.epoch_update(loss_dict, epoch, train_flag=True)\n",
    "    write_summary(summary_writer, loss_dict, train_flag=True)\n",
    "    FAR_show_sample(VPTR_Enc, VPTR_Dec, VPTR_Transformer, num_future_frames, sample, f'{ckpt_save_dir}/train_gifs_epoch{epoch}', test_phase=False)\n",
    "\n",
    "    if epoch % val_per_epochs == 0:\n",
    "        EpochAveMeter = AverageMeters(loss_name_list)\n",
    "        for idx, sample in enumerate(val_loader, 0):\n",
    "            iter_loss_dict = single_iter(VPTR_Enc, VPTR_Dec, VPTR_Disc, VPTR_Transformer, optimizer_T, optimizer_D, sample, device, lam_gan, train_flag=False)\n",
    "            EpochAveMeter.iter_update(iter_loss_dict)\n",
    "        loss_dict = EpochAveMeter.epoch_update(loss_dict, epoch, train_flag=False)\n",
    "        write_summary(summary_writer, loss_dict, train_flag=False)\n",
    "        \n",
    "        for idx, sample in enumerate(test_loader, random.randint(0, len(test_loader) - 1)):\n",
    "            FAR_show_sample(VPTR_Enc, VPTR_Dec, VPTR_Transformer, num_future_frames, sample, f'{ckpt_save_dir}/val_gifs_epoch{epoch}', test_phase=True)\n",
    "\n",
    "        torch.save({'epoch': epoch, 'VPTR_Transformer': VPTR_Transformer.state_dict(), 'optimizer_T': optimizer_T.state.dict()}, f'{ckpt_save_dir}/epoch_{epoch}.tar')\n",
    "    \n",
    "    logging.info(f'epoch: {epoch}, epoch time: {datetime.now() - epoch_st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPTR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
